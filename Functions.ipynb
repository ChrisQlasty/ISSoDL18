{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"      \n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "# srce: http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper funcion for data reading\n",
    "def readIt(dataType, _path='data//'):    \n",
    "    Inputs  = pd.read_csv(_path + 'I' + dataType+'.csv',decimal=',',sep=';',header=None).as_matrix()\n",
    "    Lengths = pd.read_csv(_path + 'L' + dataType+'.csv',decimal=',',sep=';',header=None).as_matrix()\n",
    "    Targets = pd.read_csv(_path + 'T' + dataType+'.csv',decimal=',',sep=';',header=None).as_matrix()\n",
    "    \n",
    "    return Inputs, Lengths, Targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function for reshaping 2D array of stacked sequences into 3D array, zero padded. shape=[n_examples,longest_seq,n_features]\n",
    "def ReshapeMyData(INP, LEN, TAR, n_features, longest_seq):\n",
    "    \n",
    "    #data resampling\n",
    "    scaler = 2 # -- select every _?_ sample\n",
    "           \n",
    "    a2 = np.cumsum(LEN)        \n",
    "    a1 = np.insert(a2, [0], [0])    \n",
    "    a1 = a1[:-1]    \n",
    "    \n",
    "    maxLength = int(np.floor(longest_seq / scaler))\n",
    "    LEN = np.floor(LEN / scaler).astype(dtype='int32')        \n",
    "    \n",
    "    zero_padded_INP = np.empty((LEN.shape[0], maxLength, n_features))\n",
    "\n",
    "    for i in range(LEN.shape[0]):\n",
    "        tmp = INP[a1[i]:a2[i], :]\n",
    "        tmp = tmp[1::scaler, :]\n",
    "        zero_padded = np.zeros((maxLength, n_features))\n",
    "        zero_padded[:tmp.shape[0], :] = tmp\n",
    "        zero_padded_INP[i, :, :] = zero_padded\n",
    "         \n",
    "    LEN = LEN.squeeze()\n",
    "    TAR = TAR.squeeze()\n",
    "            \n",
    "    return zero_padded_INP, TAR, LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function for selecting only the last output of sequence of given length (for classification)\n",
    "def last_relevant(output, length):\n",
    "    # srce: https://danijar.com/variable-sequence-lengths-in-tensorflow/    \n",
    "    batch_size = tf.shape(output)[0]\n",
    "    max_length = tf.shape(output)[1]\n",
    "    out_size = int(output.get_shape()[2])    \n",
    "    index = tf.range(0, batch_size) * max_length + (length - 1)\n",
    "    flat = tf.reshape(output, [-1, out_size])        \n",
    "    relevant = tf.gather(flat, index)    \n",
    "    return relevant\n",
    "\n",
    "#memory efficient version @: #https://stackoverflow.com/questions/45882401/how-to-deal-with-userwarning-converting-sparse-indexedslices-to-a-dense-tensor?noredirect=1&lq=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function for waveforms chopping \n",
    "def SmartDataChop(biosignals, select_every_nth, inp_steps, out_steps, shift, ratio, tail_for_testing=False):\n",
    "    #2500 are hardcoded\n",
    "    Xtemp = np.zeros((2500,inp_steps,biosignals.shape[1]-1)) #-1 as target vector should be taken out of inputs\n",
    "    Ytemp = np.zeros((2500,out_steps))\n",
    "\n",
    "    if(shift>=0):    \n",
    "        cnt = 0\n",
    "        for i in range(0,50000,20):    \n",
    "            #       array_name[ start_index : end_ index : step]\n",
    "            Xtemp[cnt,:,:] = biosignals.iloc[i : \n",
    "                                             i+select_every_nth*(inp_steps) : select_every_nth,1:]    \n",
    "            Ytemp[cnt,:]   = biosignals.iloc[i+select_every_nth*(inp_steps+shift-out_steps) : \n",
    "                                             i+select_every_nth*(inp_steps+shift) : select_every_nth,0]   \n",
    "            cnt = cnt + 1\n",
    "\n",
    "        np.random.seed(seed=888)\n",
    "\n",
    "        if(tail_for_testing):     \n",
    "            indexes=np.arange(2500) # cut last 1-ratio of data to constitute testing set\n",
    "        else:\n",
    "            indexes=np.random.permutation(2500) # take testing examples from within whole waveform\n",
    "        \n",
    "        Xtemp = Xtemp[indexes,:,:]\n",
    "        Ytemp = Ytemp[indexes,:]\n",
    "    else:\n",
    "        print('Error! shift must be >=0!')\n",
    "\n",
    "    training_samples = int(ratio*Xtemp.shape[0]) # lets get ratio*100% of the data for training    \n",
    "    \n",
    "    X_train = Xtemp[0:training_samples,:,:]\n",
    "    X_test = Xtemp[training_samples: ,:,:]\n",
    "\n",
    "    _Y_train = Ytemp[0:training_samples,:]\n",
    "    _Y_test = Ytemp[training_samples :,:]\n",
    "    \n",
    "    return X_train, X_test, _Y_train, _Y_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
